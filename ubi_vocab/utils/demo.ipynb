{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('ubi_vocab': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f06c84075800edc2bd11e6453ca768e797c1fd3591a69a16ca75713203271fa4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /Users/kevinzen/miniconda3/lib/python3.7/site-packages (2.1.0)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# download pre built models.\n",
    "%%python -m spacy download en_core_web_sm\n",
    "%%python -m nltk.downloader wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading existing file at ../../data/gre_vocab.csv\n",
      "2021-04-27 02:41:48,754 - main - INFO - Loading in spacy and sentence transformer models.\n",
      "2021-04-27 02:41:49,431 - transformer - INFO - Reading in pretrained model bert-base-nli-mean-tokens\n",
      "2021-04-27 02:41:49,431 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: bert-base-nli-mean-tokens\n",
      "2021-04-27 02:41:49,432 - sentence_transformers.SentenceTransformer - INFO - Did not find folder bert-base-nli-mean-tokens\n",
      "2021-04-27 02:41:49,432 - sentence_transformers.SentenceTransformer - INFO - Try to download model from server: https://sbert.net/models/bert-base-nli-mean-tokens.zip\n",
      "2021-04-27 02:41:49,434 - sentence_transformers.SentenceTransformer - INFO - Load SentenceTransformer from folder: /Users/kevinzen/.cache/torch/sentence_transformers/sbert.net_models_bert-base-nli-mean-tokens\n",
      "2021-04-27 02:41:51,186 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n",
      "2021-04-27 02:41:51,188 - main - INFO - Getting replaced sentences for each news article.\n",
      "2021-04-27 02:41:51,453 - transformer - INFO - Starting to get embedding\n",
      "2021-04-27 02:41:51,453 - transformer - INFO - Starting to embed 3 text with bert-base-nli-mean-tokens, workers : 8\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 24.04it/s]\n",
      "2021-04-27 02:41:51,503 - transformer - INFO - Starting to embed 3 text with bert-base-nli-mean-tokens, workers : 8\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 23.88it/s]\n",
      "2021-04-27 02:41:51,552 - transformer - INFO - Calculating cosine similarity scores\n",
      "2021-04-27 02:41:51,553 - main - INFO - word: 3, syn : 3, orig_text : 3, mod_text : 3, sim_score : 3\n",
      "2021-04-27 02:41:51,563 - main - INFO - Adding LESK results\n",
      "2021-04-27 02:41:51,572 - main - INFO - Replacing the entire article (2, 2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    This is an article about the detrimental effects of not learning vocabulary.  This program seeks to create a quotidian exercise for learning vocabulary over time.\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import sys\n",
    "import nltk\n",
    "\n",
    "from api import UbiVocab\n",
    "\n",
    "data_dir = \"../../data/\"\n",
    "ubi_vocab = UbiVocab(data_dir = data_dir)\n",
    "article = (f\"This is an article about the damaging effects of not learning vocabulary. \"\n",
    "                f\" This program seeks to create a routine exercise for learning vocabulary over time.\")\n",
    "\n",
    "# Process the input article above.\n",
    "ubi_vocab.process_article(article = article, num_sentences = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    This is an article about the detrimental effects of not learning vocabulary.  This program seeks to create a quotidian exercise for learning vocabulary over time.\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# View the new article with replaced words.\n",
    "ubi_vocab.new_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          word       syn  \\\n",
       "0  detrimental  damaging   \n",
       "1      mundane   routine   \n",
       "2    quotidian   routine   \n",
       "\n",
       "                                                                             orig_text  \\\n",
       "0             This is an article about the damaging effects of not learning vocabulary   \n",
       "1    This program seeks to create a routine exercise for learning vocabulary over time   \n",
       "2    This program seeks to create a routine exercise for learning vocabulary over time   \n",
       "\n",
       "                                                                                mod_text  \\\n",
       "0            This is an article about the detrimental effects of not learning vocabulary   \n",
       "1      This program seeks to create a mundane exercise for learning vocabulary over time   \n",
       "2    This program seeks to create a quotidian exercise for learning vocabulary over time   \n",
       "\n",
       "   sim_score syn_pos_context    syn_pos                   synset  \\\n",
       "0   0.983425       adjective  adjective  Synset('damaging.s.01')   \n",
       "1   0.787758       adjective  adjective  Synset('everyday.s.01')   \n",
       "2   0.930106       adjective  adjective  Synset('everyday.s.01')   \n",
       "\n",
       "                      lesk  \n",
       "0  Synset('damaging.s.01')  \n",
       "1   Synset('mundane.s.03')  \n",
       "2  Synset('everyday.s.01')  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word</th>\n      <th>syn</th>\n      <th>orig_text</th>\n      <th>mod_text</th>\n      <th>sim_score</th>\n      <th>syn_pos_context</th>\n      <th>syn_pos</th>\n      <th>synset</th>\n      <th>lesk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>detrimental</td>\n      <td>damaging</td>\n      <td>This is an article about the damaging effects of not learning vocabulary</td>\n      <td>This is an article about the detrimental effects of not learning vocabulary</td>\n      <td>0.983425</td>\n      <td>adjective</td>\n      <td>adjective</td>\n      <td>Synset('damaging.s.01')</td>\n      <td>Synset('damaging.s.01')</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mundane</td>\n      <td>routine</td>\n      <td>This program seeks to create a routine exercise for learning vocabulary over time</td>\n      <td>This program seeks to create a mundane exercise for learning vocabulary over time</td>\n      <td>0.787758</td>\n      <td>adjective</td>\n      <td>adjective</td>\n      <td>Synset('everyday.s.01')</td>\n      <td>Synset('mundane.s.03')</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>quotidian</td>\n      <td>routine</td>\n      <td>This program seeks to create a routine exercise for learning vocabulary over time</td>\n      <td>This program seeks to create a quotidian exercise for learning vocabulary over time</td>\n      <td>0.930106</td>\n      <td>adjective</td>\n      <td>adjective</td>\n      <td>Synset('everyday.s.01')</td>\n      <td>Synset('everyday.s.01')</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# View the underlying reasons for the replacement.\n",
    "ubi_vocab.highlights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}